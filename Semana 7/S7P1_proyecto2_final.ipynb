{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier,XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "data_training = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "data_testing = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de preprocesamiento de texto\n",
    "# Función de preprocesamiento de texto\n",
    "def preprocess_text_manual(text):\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Eliminar caracteres no alfabéticos\n",
    "    tokens = text.split()  # Tokenizar\n",
    "    # Eliminar algunas stopwords básicas\n",
    "    stopwords = {'the', 'and', 'in', 'to', 'of', 'a', 'is', 'that', 'with', 'as', 'for', 'on', 'at', 'by', 'an'}\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "data_training['clean_plot'] = data_training['plot'].apply(preprocess_text_manual)\n",
    "data_testing['clean_plot'] = data_testing['plot'].apply(preprocess_text_manual)\n",
    "\n",
    "# Convertir géneros a etiquetas binarias\n",
    "mlb = MultiLabelBinarizer()\n",
    "data_training['genres'] = data_training['genres'].apply(eval)  # Convertir las listas de cadenas a listas de Python\n",
    "genres_binary = mlb.fit_transform(data_training['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorización usando TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(data_training['clean_plot'])\n",
    "X_test = vectorizer.transform(data_testing['clean_plot'])\n",
    "\n",
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, genres_binary, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regresion Logistica</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAUC: 0.8751628393523943\n"
     ]
    }
   ],
   "source": [
    "# Entrenar un clasificador de regresión logística\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "clf = MultiOutputClassifier(log_reg, n_jobs=-1)\n",
    "clf.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = clf.predict_proba(X_val_split)\n",
    "y_val_pred = np.array([pred[:, 1] for pred in y_val_pred]).T  # Convertir las probabilidades a la forma correcta\n",
    "\n",
    "# Calcular el MCAUC\n",
    "mauc = roc_auc_score(y_val_split, y_val_pred, average='macro')\n",
    "print(f'MCAUC: {mauc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>XGBClassifier</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenar un regresor XGB\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xgb_reg \u001b[38;5;241m=\u001b[39m \u001b[43mXGBClassifier\u001b[49m(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;66;03m#reg:logistic\u001b[39;00m\n\u001b[0;32m      3\u001b[0m reg \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(xgb_reg, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(X_train_split, y_train_split)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Entrenar un regresor XGB\n",
    "xgb_reg = XGBRegressor(objective='reg:logistic', n_estimators=10, max_depth=40, learning_rate=0.1)#reg:logistic\n",
    "reg = MultiOutputClassifier(xgb_reg, n_jobs=-1)\n",
    "reg.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_val_pred = reg.predict(X_val_split)\n",
    "# y_val_pred = np.array([pred[:, 1] for pred in y_val_pred]).T\n",
    "# Calcular el MCAUC\n",
    "mauc = roc_auc_score(y_val_split, y_val_pred, average='macro')\n",
    "print(f'MCAUC: {mauc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_test_pred = clf.predict_proba(X_test)\n",
    "y_test_pred = np.array([pred[:, 1] for pred in y_test_pred]).T  # Convertir las probabilidades a la forma correcta\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Guardar predicciones en formato exigido en la competencia de Kaggle\n",
    "submission = pd.DataFrame(y_test_pred, index=data_testing.index, columns=cols)\n",
    "submission.to_csv('pred_genres_text_RF.csv', index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
